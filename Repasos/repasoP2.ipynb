{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística\n",
    "\n",
    "Es un modelo que se utiliza para estimar la probabilidad de que ocurra un evento, por ejemplo, con el dataset del Titanic, utilizamos la regresión logística para estimar la probabilidad de que una persona sobreviva. Otro uso sería para estimar la probabilidad de impago de un cliente. \n",
    "\n",
    "Dependiendo de la situación y de el evento que se esté modelando, se definirá un límite para determinar si el evento ocurrió o no ocucurrió, por ejemplo: si $p>0.5$ se clasificará como $1$ (si ocurrió) y si $p<0.5$ se clasificará como $0$ (no ocurrió).\n",
    "\n",
    "La hipótesis de este modelo sería la función sigmoide:\n",
    "\n",
    "$$h_\\theta=\\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "Donde\n",
    "\n",
    "$$z=\\theta^T X $$\n",
    "\n",
    "Esta función es utilizada dado que sus valores siempre estarán entre 0 y 1, por lo que es de grán utilidad al momento estimar probabilidades.\n",
    "\n",
    "### Concepto de máxima verosimilitud\n",
    "\n",
    "La función de verosimilitud de un conjunto de datos es:\n",
    "\n",
    "$$\n",
    "L(\\theta, \\sigma^2) = \\prod_{i=1}^{m} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\theta^T X_i)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "Para elimiar el exponente y la multiplicatoria aplicamos el logaritmo\n",
    "\n",
    "$$\n",
    "\\log L(\\theta, \\sigma^2) = \\sum_{i=1}^{m} \\left( -\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(y_i - \\theta^T X_i)^2}{2\\sigma^2} \\right)\n",
    "$$\n",
    "\n",
    "### Relación con OLS  \n",
    "\n",
    "Para **maximizar la verosimilitud respecto a $\\theta$**, ignoramos términos constantes:\n",
    "\n",
    "$$\n",
    "\\max_{\\theta} \\sum_{i=1}^{m} -\\frac{(y_i - \\theta^T X_i)^2}{2\\sigma^2}\n",
    "$$\n",
    "\n",
    "Esto equivale a **minimizar el error cuadrático**:\n",
    "\n",
    "$$\n",
    "\\min_{\\theta} \\sum_{i=1}^{m} (y_i - \\theta^T X_i)^2\n",
    "$$\n",
    "\n",
    "Entonces, minimizar el error cuadrático con **OLS** es lo mismo que **maximizar la verosimilitud** bajo una **distribución normal de los errores**.\n",
    "\n",
    "### ¿Cómo estimamos los $\\theta$?\n",
    "\n",
    "Si asumimos que:\n",
    "\n",
    "$$P(y=1 | x;\\theta)=h_\\theta(x)$$\n",
    "$$P(y=0 | x;\\theta)= 1 - h_\\theta(x)$$\n",
    "\n",
    "Entonces podemos escribir la función de verosimilitud para la regresión logística de la siguiente manera dado que $y$ sigue una distribución de Bernoulli:\n",
    "\n",
    "$$L(\\theta)=\\prod_{i=1}^{m}p(y_i | X_i;\\theta) = \\prod_{i=1}^{m}(h_\\theta(x))^{y_i}(1-h_\\theta(x))^{1-y_i}$$\n",
    "\n",
    "Sacamos logaritmo para quitar el exponencial y así obtenemos la función de pérdida:\n",
    "\n",
    "$$J(\\theta)=\\log{L(\\theta)} = \\frac{1}{m} \\sum_{i=1}^m y_i \\log{h_\\theta (x)} + (1-y_i)\\log{(1-h_\\theta) (x)}$$\n",
    "\n",
    "Dado que queremos maximizar la verosimilitud, hay que aplicar el ascenso en gradiente, que adiferencia del descenso en gradiente, en lugar de restar la derivada, en este caso habrá que sumarla, entonces:\n",
    "\n",
    "Repetir hasta convergencia\n",
    "\n",
    "$$\\theta_j = \\theta_j + \\alpha \\frac{\\partial J}{\\partial \\theta_j} $$\n",
    "\n",
    "Donde $\\alpha$ es el learning rate.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odds\n",
    "\n",
    "Los odds representan la razón entre el éxito y el fracaso, y la manera de calcularlo es de la siguiente manera:\n",
    "\n",
    "$$\\text{odds} = \\frac{p}{1-p}$$\n",
    "\n",
    "Por ejemplo, si un equipo gana 2 a 5, la razón sería 2/5, dado que:\n",
    "\n",
    "$$ p=\\frac{2}{2+5} = \\frac{2}{7}$$\n",
    "\n",
    "$$ \\text{odss} =\\frac{2/7}{1-2/7}=\\frac{2}{5}$$\n",
    "\n",
    "# Log odds\n",
    "\n",
    "Por el comportamiento exponencial de los odds, es complicado utilizarlos en una regresión, por lo que se aplica el logaritmo para linealizar el comportamiento\n",
    "\n",
    "$$ \\log{\\text{odds}} = \\log{\\frac{p}{1-p}} $$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax\n",
    "\n",
    "Es un modelo de clasificación similar a la regresión logística, sin embargo, aquí hay más de una clasificación, es decir, no solo se determina si el evento sucedió o no sucedió. Por ejemplo, se clasificará como A si $p<0.3$, se clasificará como B si $0.3<p<0.6$ y se clasificará como C si $p>0.6$.\n",
    "\n",
    "Para calcularlo se utiliza una función que convierte los resultados de la función lineal en probabilidades:\n",
    "\n",
    "$$ P(y=k|X) = \\frac{\\text{exp}(\\text{w}_k \\text{x} + b_k)}{\\sum_{j=1}^{k} \\text{exp}(\\text{w}_k \\text{x} + b_k) } $$\n",
    "\n",
    "Viéndolo de forma numérica:\n",
    "\n",
    "Si tenemos que $ z_1=2$      ,$z_2=1$,      $z_3=-1$\n",
    "\n",
    "Aplicando softmax:\n",
    "\n",
    "$$P(y=1) =  \\frac{e^2}{e^2 + e^1 + e^{-1}} = 0.72 $$\n",
    "$$P(y=2) =  \\frac{e^1}{e^2 + e^1 + e^{-1}} = 0.26 $$\n",
    "$$P(y=3) =  \\frac{e^{-1}}{e^2 + e^1 + e^{-1}} = 0.04 $$\n",
    "\n",
    "Gracias a softmax, podemos saber que la clase 1 es la más probable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis del discriminante lineal\n",
    "\n",
    "Es un modelo, el cual asume que los datos de cada clase siguen un distribución normal multivariada, y gracias a este supuesto se pueden estimr las probabilidades de pertenecer a una de las clases. \n",
    "\n",
    "Se utiliza la función: \n",
    "$$\n",
    "P(\\mathbf{x} | y = k) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma_k|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x} - \\mu_k)^T \\Sigma_k^{-1} (\\mathbf{x} - \\mu_k)\\right)\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $\\mathbf{x}$ es el vector de características.\n",
    "- $\\mu_k$ es el vector de medias de la clase \\( k \\).\n",
    "- $\\Sigma_k$ es la matriz de covarianza de la clase \\( k \\).\n",
    "- $\\Sigma_k|$ es el determinante de la matriz de covarianza.\n",
    "\n",
    "Para calcular la probabilidad de pertenecer a una de las clases se utiliza la regla de bayes y la clase a elegir será aquella con la probabilidad más alta con la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "P(y = k | \\mathbf{x}) = \\frac{P(\\mathbf{x} | y = k) P(y = k)}{P(\\mathbf{x})}\n",
    "$$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales\n",
    "\n",
    "Es un modelo en el que se pueden realizar transformaciones a los datos antes de realizar las predicciones. El modelo primero recibe datos a la entrada y despues pasan por $n$ capas donde se realizarán transformaciones hasta llegar a la capa de salida y pasarán por una función de activación que puede o no cambiar cada capa.\n",
    "\n",
    "### Forward propagation\n",
    "\n",
    "Entran los datos y se realiza una combinación lineal de los datos con pesos iniciales, más un sesgo:\n",
    "$$\n",
    "z^{[l]} = W^{[l]} a^{[l-1]} + b^{[l]}\n",
    "$$\n",
    "donde:\n",
    "- $a^{[l-1]}$ son las activaciones (o salidas) de la capa anterior.\n",
    "- $W^{[l]}$ es la matriz de pesos que conecta la capa anterior con la capa $l$.\n",
    "- $b^{[l]}$ es el vector de sesgos de la capa $l$.\n",
    "\n",
    "Luego pasan por la función de activación para introducir no linealidad al modelo. Esta función de activación $g(z)$ puede ser:\n",
    "$$\\text{ReLU}(x) = \\max(0, x)$$\n",
    "$$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "$$\\text{tanh}(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$$\n",
    "\n",
    "### Backpropagation\n",
    "\n",
    "Es un procedimiento de suma importancia para el entrenamiento de una red neuronal, ya que calcula de manera eficiente los gradientes y así poder calcular el error de cada capa utilizando la función de pérdida.\n",
    "\n",
    "Proceso:\n",
    "\n",
    "1. Primero se realiza Forward Propagation.\n",
    "2. Calcular el error de la capa de salida como la diferencia entre la salida predicha $a^{[L]}$ y el valor real $y$ donde $J$ es la función de pérdida.\n",
    "\n",
    "$$\\delta^{[L]} = \\frac{\\partial J}{\\partial z^{[L]}} = (a^{[L]} - y) \\odot g'(z^{[L]})$$\n",
    "\n",
    "3. Ahora, utilizando la regla de la cadena,se realiza la propagación del error hacia atras para cada capa $l$ de $L-1$ hasta la primera capa oculta. De esta manera cada parámetro podrá ajustarse dependiendo de su contribución al error final. se calcula de la siguiente manera:\n",
    "$$\n",
    "\\delta^{[l]} = \\left(W^{[l+1]}\\right)^T \\delta^{[l+1]} \\odot g'(z^{[l]})\n",
    "$$\n",
    "\n",
    "4. Una vez calculados los errores de cada capa, habrá que calcular los gradientes con respecto a cada peso y sesgo:\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{[l]}} = \\delta^{[l]} \\left(a^{[l-1]}\\right)^T\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial b^{[l]}} = \\delta^{[l]}\n",
    "$$\n",
    "\n",
    "5. Repetir hasta minimizar la función de costo actualizando los parámetros y con una tasa de aprendizaje determinada\n",
    "\n",
    "$$\n",
    "W^{[l]} = W^{[l]} - \\alpha \\frac{\\partial J}{\\partial W^{[l]}}\n",
    "$$\n",
    "$$\n",
    "b^{[l]} = b^{[l]} - \\alpha \\frac{\\partial J}{\\partial b^{[l]}}\n",
    "$$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC\n",
    "\n",
    "Es un métrica que nos sirve para medir que tan bueno es un modelo de clasificación. En otras palabras nos dice que tan bien un modelo distinguir entre sus clases. Esta métrica puede ser representada gráficamente como el área bajo la curva ROC.\n",
    "\n",
    "Además, suponiendo que estamos trabajando con la probabilidad de impago, el AUC puede interpretarse como la probabilidad de que un individuo seleccionado al azar que si pagó tenga una predicción mayor al individuo que no pagó."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
