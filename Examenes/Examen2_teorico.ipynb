{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "203c39ed",
   "metadata": {},
   "source": [
    "# ***Examen teórico módulo 2***\n",
    "### Luis Eduardo Jiménez del Muro - 20/03/2025\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5421100",
   "metadata": {},
   "source": [
    "## **Sección 1: Regresión Logística** (30 puntos)  \n",
    "\n",
    "1. **(10 pts)** Explica la diferencia entre la regresión logística **lineal** y la **polinomial**. ¿En qué casos es recomendable usar la versión polinomial?  \n",
    "\n",
    "La única diferencia es que al momento de hacer nuestra regresión logística, nuestra Z de la función sigmoide podrá verse de las siguientes maneras\n",
    "\n",
    "### Regresión logística lineal\n",
    "\n",
    "$$ \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n $$\n",
    "\n",
    "### Regresión logística polinomial\n",
    "\n",
    "$$ \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2^2 + \\beta_3 X_3^4 + ... + \\beta_n X_n^2 $$\n",
    "\n",
    "La situación de utilizar una u otra dependerá de si existen relaciones entre las variables que sean o no sean lineales.\n",
    "\n",
    "Utilizar un polinomial podría ser conveniente para poder entrenar al modelo con relaciones no lineales, sin embargo, hay que recordar que los modelos polinomiales tienden a la memorización de datos u overfitting.\n",
    "\n",
    "2. **(10 pts)** Explica como mediante decenso en gradiente y maxima verosimilitud creamos una regresión lógisitca  \n",
    "\n",
    "La probabilidad en este modelo se calcula con la función sigmoide:\n",
    "\n",
    "$$p=\\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "Donde\n",
    "\n",
    "$$z=\\theta^T X $$\n",
    "\n",
    "Dado que la variable de respuesta es 0 o 1, significa que sigue una Bernoulli y su función de verosimilitud es:\n",
    "\n",
    "$$L(\\theta)=\\prod_{i=1}^{m}p(y_i | X_i;\\theta) = \\prod_{i=1}^{m}(h_\\theta(x))^{y_i}(1-h_\\theta(x))^{1-y_i}$$\n",
    "\n",
    "Donde $h_\\theta$ es nuestra función de probabilidad o sigmoide.\n",
    "\n",
    "Para deshacernos de las multiplicatorias y exponenciales podemos tomar el logaritmo de la verosimilitud y así poder obtener la función de pérdida:\n",
    "\n",
    "$$J(\\theta)=\\log{L(\\theta)} = \\frac{1}{m} \\sum_{i=1}^m y_i \\log{h_\\theta (x)} + (1-y_i)\\log{(1-h_\\theta) (x)}$$\n",
    "\n",
    "Dado que queremos maximizar la verosimilitud, hay que aplicar el ascenso en gradiente, que adiferencia del descenso en gradiente, en lugar de restar la derivada, en este caso habrá que sumarla, entonces:\n",
    "\n",
    "Repetir hasta convergencia\n",
    "\n",
    "$$\\theta_j = \\theta_j + \\alpha \\frac{\\partial J}{\\partial \\theta_j} $$\n",
    "\n",
    "Donde $\\alpha$ es el learning rate.\n",
    "\n",
    "3. **(10 pts)** Explica el concepto de **odds** y **log-odds** en regresión logística. ¿Por qué la regresión logística predice el **log-odds** en lugar de la probabilidad directamente? Justifica esto   \n",
    "\n",
    "Los odds representan la razón entre el éxito y el fracaso, y la manera de calcularlo es de la siguiente manera:\n",
    "\n",
    "$$\\text{odds} = \\frac{p}{1-p}$$\n",
    "\n",
    "Por el comportamiento exponencial de los odds, es complicado utilizarlos en una regresión, por lo que se aplica el logaritmo para linealizar el comportamiento\n",
    "\n",
    "$$ \\log{\\text{odds}} = \\log{\\frac{p}{1-p}} $$\n",
    "\n",
    "Para demostrar que la regresión logística predice el log ods podemos verlo de la siguiente manera, igualamos logodds a la predicción y despejamos $p$:\n",
    "\n",
    "$$ \\log{\\frac{p}{1-p}} = \\theta X$$\n",
    "\n",
    "Entonces\n",
    "\n",
    "$$p=\\frac{1}{1+e^{-e^{\\theta X}}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c6cac",
   "metadata": {},
   "source": [
    "## **Sección 2: Área Bajo la Curva (AUC)** (20 puntos)  \n",
    "\n",
    "7. **(5 pts)** Define la **curva ROC** y el AUC. ¿Qué tiene de especial\n",
    "\n",
    "### AUC\n",
    "\n",
    "Es un métrica que nos sirve para medir que tan bueno es un modelo de clasificación. En otras palabras nos dice que tan bien un modelo puede distinguir entre sus clases. Esta métrica puede ser representada gráficamente como el área bajo la curva ROC.\n",
    "\n",
    "### Curva ROC\n",
    "\n",
    "Es una curva que se crea a partir de graficar el sensitiviy vs 1-specificity y nos sirve para ver que tan buen desempeño tiene un modelo de clasificación de únicamente 2 categorías (1 o 0).\n",
    "\n",
    "**Sensitivity**\n",
    "\n",
    "De los que pertenecen a 1, que porcentaje logró predecir correctamente el modelo.\n",
    "\n",
    "$$\\text{Sensitivity} = \\frac{\\text{True positive (TP)}}{\\text{True positive (TP)} + \\text{False Negative (FN)}}$$\n",
    "\n",
    "**Specificity**\n",
    "\n",
    "De los que pertenecen a 0, que porcentaje logró predecir correctamente el modelo.\n",
    "\n",
    "$$\\text{Specificity} = \\frac{\\text{True Negative (TN)}}{\\text{True Negative (TN)} + \\text{False Positive (FP)}}$$\n",
    "\n",
    "La forma de ver qué tan bueno es nuestro modelo es gracias al AUC, el cual es el área bajo la curva generada por sensitiviy vs 1-specificity, en dónde:\n",
    "\n",
    "+ Si AUC = 1, es un excelente modelo.\n",
    "+ Si AUC = 0.5 es un mal modelo.\n",
    "+ Si AUC < 0.5 es mejor no hacer el modelo.\n",
    "\n",
    "\n",
    "8. **(5 pts)** Cuando hacemos una curva ROC, siempre ponemos una diagonal, explica que es esa diagonal  \n",
    "\n",
    "\n",
    "En esta gráfica se muestra siempre una linea diagonal que cruza de (0,0) a (1,1), la cual, si la gráfica de sensitiviy vs 1-specificity (ROC) se ajusta a esta diagonal, quiere decir que el ajuste de nuestro modelo es muy malo. Mientras que si nuestra curva está por encima de la diagonal, indica que nuestro modelo es mejor que no haber hecho nada y podría decirse que si nuestro modelo se ajusta a la diagonal es prácticamente lo mismo que haber hecho un modelo al azar, el cual no puede predecir.\n",
    "\n",
    "9. **(5 pts)** Un modelo tiene un **AUC de 0.85**. Explica qué significa esto en términos de su capacidad de clasificación.  \n",
    "\n",
    "Es la probabilidad de que la predicción de una entrada al azar tenga una predicción mayor a otra entrada que no pertenece a ese grupo. En otras palabras, si queremos predecir si un cliente pagó o no pagó, tendríamos un 85% de probabilidades de que el que si pagó obtenga una probabilidad mayor al que no pagó.\n",
    "\n",
    "10. **(5 pts)** Un modelo tiene accuracy de 99% pero AUC de 0.5%, ¿Cómo es que esto podría suceder?\n",
    "\n",
    "ESto se debe a que la forma en que se calcula el accuracy únicamente toma en cuenta las predicciones de los 1 que si son 1 y de los 0 que son 0 sin realizar una ponderación por la cantidad de datos que tiene cada una.\n",
    "\n",
    "Por ejemplo, si en los datos hay 99 datos que son 1 y 1 que es 0, gracias a la alta cantidad de 1 el modelo puede equivocarse con el 0 y al mismo tiempo acertar con 99 unos. Si esto sucede quiere decir que el modelo tiene un accuray de 99%, pero debido a que no fue capaz de predecir correctamente los 0 obendría un AUC terrible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58182883-edf4-410e-9fb5-3cc408d49dfb",
   "metadata": {},
   "source": [
    "## **Sección 3: Análisis del Discriminante Lineal (LDA)** (10 puntos)  \n",
    "\n",
    "11. **(10 pts)** ¿Qué es el análisis del discriminante lineal? ¿En que casos lo usarías? (gausiano)\n",
    "\n",
    "Es un modelo, el cual asume que los datos de cada clase siguen un distribución normal multivariada, y gracias a este supuesto se pueden estimr las probabilidades de pertenecer a una de las clases. \n",
    "\n",
    "Se utiliza la función: \n",
    "$$\n",
    "P(\\mathbf{x} | y = k) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma_k|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x} - \\mu_k)^T \\Sigma_k^{-1} (\\mathbf{x} - \\mu_k)\\right)\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $\\mathbf{x}$ es el vector de características.\n",
    "- $\\mu_k$ es el vector de medias de la clase \\( k \\).\n",
    "- $\\Sigma_k$ es la matriz de covarianza de la clase \\( k \\).\n",
    "- $\\Sigma_k|$ es el determinante de la matriz de covarianza.\n",
    "\n",
    "Para calcular la probabilidad de pertenecer a una de las clases se utiliza la regla de bayes y la clase a elegir será aquella con la probabilidad más alta con la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "P(y = k | \\mathbf{x}) = \\frac{P(\\mathbf{x} | y = k) P(y = k)}{P(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "**Casos de uso** \n",
    "\n",
    "* Cuando tenemos poca cantidad de datos este modelo es mejor que la regresión logística.\n",
    "* Cuando las variables en efecto siguen una distribución normal multivariada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa6d116",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "## Sección 4: Cross validation  (10 puntos)  \n",
    "\n",
    "12. **(10 pts)** ¿Qué es grid search? ¿qué es random search? Explica las diferencias y cuando usarías cada uno  \n",
    "\n",
    "### Grid search \n",
    "\n",
    "Se basa en probar todas las combinaciones posibles de los hiperparámtros hasta encontrar la que obtenga un mejor ajuste en el modelo.\n",
    "\n",
    "**Casos de uso**\n",
    "- Cuando se quiere encontrar la mejor combinación posible del conjunto de hiperparámtros, en otras palabras, la combinación perfecta y el consumo computacional no es un problema, dado que si el modelo tiene muchos datos esto podría tardar mucho tiempo y mucho consumo para las computadoras.\n",
    "\n",
    "### RandomSearch \n",
    "\n",
    "A diferencia del grid search, este no prueba todas las combinaciones posibles, sino que selecciona aleatorios dentro de un rango.\n",
    "\n",
    "**Casos de uso**\n",
    "- Cuando no nos podemos permitir gastar tantos recursos (dinero y tiempo) de correr un grid search, dado que el Random Search es mas rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e180947",
   "metadata": {},
   "source": [
    "## **Sección 5: Redes Neuronales y Perceptrón Multicapa** (20 puntos)  \n",
    "\n",
    "13. **(5 pts)** Explica que es una red neuronal, que hace, como funciona, etc. \n",
    "\n",
    "Es un modelo en el que se pueden realizar transformaciones a los datos antes de realizar las predicciones. El modelo primero recibe datos a la entrada y despues pasan por $n$ capas donde se realizarán transformaciones hasta llegar a la capa de salida y pasarán por una función de activación que puede o no cambiar cada capa. Lo anterior se le conoce como el forward propagation. Posteriormente ocurre el proceso de backpropagation, en donde ocurre el entrenamiento del modelo, dado que desde la capa de salida hasta la de entrada se distribuye el error por todas las capas intermedias. Al final para encontrar los pesos que obtienen al mejor modelo se realiza el descenso en gradiente modificando los coeficientes hasta minimizar el error.\n",
    " \n",
    "14. **(5 pts)** ¿Cuál es el propósito de la **backpropagation** en el entrenamiento de redes neuronales?\n",
    "\n",
    "Es un procedimiento de suma importancia para el entrenamiento de una red neuronal, ya que calcula el descenso en gradiente utilizando las derivadas parciales de las funciones de costo con respecto a cada uno de los pesos de de los sesgos que son añadidos en el modelo. Así se pueden lograr los coeficientes ótimos que a lo largo de todas las capas de la red neuronal logren minimizar el error.\n",
    "\n",
    "15. **(5 pts)** A grandes rasgos, explica como obtenemos los coeficientes de una red neuronal  \n",
    "\n",
    "Para encontrar los coeficientes tenemos que utilizar un descenso en gradiente, donde utilicemos todo lo calculado en el back propagation. Gracias a lo calculado anteriormente podemos conocer todas las derivaciones de las funciones de pérdida con base a cada parámetro yéndonos hacia atrás hasta la capa de entrada de la red neuronal.\n",
    "\n",
    "1. Calcular el error de la capa de salida como la diferencia entre la salida predicha $a^{[L]}$ y el valor real $y$ donde $J$ es la función de pérdida.\n",
    "\n",
    "$$\\delta^{[L]} = \\frac{\\partial J}{\\partial z^{[L]}} = (a^{[L]} - y) \\odot g'(z^{[L]})$$\n",
    "\n",
    "2. Ahora, utilizando la regla de la cadena,se realiza la propagación del error hacia atras para cada capa $l$ de $L-1$ hasta la primera capa oculta. De esta manera cada parámetro podrá ajustarse dependiendo de su contribución al error final. se calcula de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\\delta^{[l]} = \\left(W^{[l+1]}\\right)^T \\delta^{[l+1]} \\odot g'(z^{[l]})\n",
    "$$\n",
    "\n",
    "3. Una vez calculados los errores de cada capa, habrá que calcular los gradientes con respecto a cada peso y sesgo:\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial W^{[l]}} = \\delta^{[l]} \\left(a^{[l-1]}\\right)^T\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial b^{[l]}} = \\delta^{[l]}\n",
    "$$\n",
    "\n",
    "\n",
    "Entonces, el descenso en gradiente será repetir hasta minimizar la función de costo actualizando los parámetros y con una tasa de aprendizaje determinada\n",
    "\n",
    "$$\n",
    "W^{[l]} = W^{[l]} - \\alpha \\frac{\\partial J}{\\partial W^{[l]}}\n",
    "$$\n",
    "$$\n",
    "b^{[l]} = b^{[l]} - \\alpha \\frac{\\partial J}{\\partial b^{[l]}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dbde44",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "## **Sección 6: Softmax** (10 puntos)  \n",
    "16. **(5 pts)** Explica que es softmax, para que sirve y como se calcula\n",
    "\n",
    "Es un modelo de clasificación similar a la regresión logística, sin embargo, aquí hay más de una clasificación, es decir, no solo se determina si el evento sucedió o no sucedió. Por ejemplo, se clasificará como A si $p<0.3$, se clasificará como B si $0.3<p<0.6$ y se clasificará como C si $p>0.6$.\n",
    "\n",
    "Para calcularlo se utiliza una función que convierte los resultados de la función lineal en probabilidades:\n",
    "\n",
    "$$ P(y=k|X) = \\frac{\\text{exp}(\\text{w}_k \\text{x} + b_k)}{\\sum_{j=1}^{k} \\text{exp}(\\text{w}_k \\text{x} + b_k) } $$\n",
    "\n",
    "Despues de calcularlo para cada entrada, se clasificará de acuerdo a la clasificación que obtenga una probabilidad mayor.\n",
    "\n",
    "\n",
    "## **Puntaje Total: 100 puntos** \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
